{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34b6d1ec",
   "metadata": {},
   "source": [
    "# Start with traditional NLP techniques before deep learning:\n",
    "1. <b>Tokenization</b> (splitting text into words/tokens)\n",
    "2. <b>Stemming & Lemmatization</b>\n",
    "3. <b>Bag-of-Words & TF-IDF</b>\n",
    "4. <b>Word Embeddings</b> (Word2Vec, GloVe, FastText)\n",
    "5. <b>Part-of-Speech Tagging</b>\n",
    "6. <b>Named Entity Recognition (NER)</b>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
